# Set everything to be logged to console
log4j.rootCategory=WARN,Console

# Define the console appender
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Set log level for your application (can adjust as needed)
#application log
log4j.logger.learn.spark.practice.vaishu=INFO,Console,file
log4j.additivity.learn.spark.practice=false

#define rolling file appender
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=${spark.yarn.app.container.log.dir}/${logfile.name}.log
#Define the following in java System
#-Dlog4j.configuration=file:log4j2.properties
#-Dlogfile.name=hello-spark
#-Dlogfile.yarn.app.container.log.dir=app-logs
log4j.appender.file.ImmediateFlush=true
log4j.appender.file.Append=false
log4j.appender.file.MaxFileSize=500MB
log4j.appender.file.MaxBackupIndex=2
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.conversionPatter=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n


# Set log level for Spark
log4j.logger.org.apache.spark=WARN
log4j.logger.org.spark-project=WARN
log4j.logger.org.apache.hadoop=WARN
log4j.logger.org.apache.kafka=WARN
log4j.logger.org.apache.zookeeper=WARN

